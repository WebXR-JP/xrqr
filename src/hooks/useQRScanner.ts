import jsQR from 'jsqr'
import { useEffect, useRef, useState, useCallback } from 'react'

export const useQRScanner = (onScan: (data: string) => void) => {
  const videoRef = useRef<HTMLVideoElement>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const [isScanning, setIsScanning] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [debugInfo, setDebugInfo] = useState<string[]>([])
  const hasLoggedScanStart = useRef(false)
  const frameCount = useRef(0)

  const addDebugInfo = (message: string) => {
    setDebugInfo(prev => [...prev.slice(-4), `${new Date().toLocaleTimeString()}: ${message}`])
  }

  const startScanning = useCallback(async () => {
    try {
      addDebugInfo('ğŸ” QRã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹')
      const hasMediaDevices = !!navigator.mediaDevices
      const hasGetUserMedia = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)
      addDebugInfo(`ğŸ“± ãƒ–ãƒ©ã‚¦ã‚¶å¯¾å¿œ: MediaDevices=${hasMediaDevices}, getUserMedia=${hasGetUserMedia}`)

      // ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ‡ãƒã‚¤ã‚¹APIã®ãƒãƒªãƒ•ã‚£ãƒ«ï¼ˆHMDå¯¾å¿œï¼‰
      if (navigator.mediaDevices === undefined) {
        addDebugInfo('âš ï¸ mediaDevicesæœªå®šç¾© - ãƒãƒªãƒ•ã‚£ãƒ«é©ç”¨')
        ;(navigator as any).mediaDevices = {}
      }

      if (!navigator.mediaDevices.getUserMedia) {
        addDebugInfo('âš ï¸ getUserMediaæœªå®šç¾© - ãƒ¬ã‚¬ã‚·ãƒ¼APIä½¿ç”¨')
        ;(navigator as any).mediaDevices.getUserMedia = function(constraints: MediaStreamConstraints) {
          const getUserMedia = (navigator as any).webkitGetUserMedia || (navigator as any).mozGetUserMedia
          if (!getUserMedia) {
            return Promise.reject(new Error('getUserMedia is not implemented in this browser'))
          }
          return new Promise(function(resolve, reject) {
            getUserMedia.call(navigator, constraints, resolve, reject)
          })
        }
      }

      // ã¾ãšåŸºæœ¬çš„ãªã‚¢ã‚¯ã‚»ã‚¹æ¨©ã‚’å–å¾—ï¼ˆå‚è€ƒã‚³ãƒ¼ãƒ‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
      addDebugInfo('ğŸ¥ åŸºæœ¬ã‚¢ã‚¯ã‚»ã‚¹æ¨©å–å¾—...')
      const tempStream = await navigator.mediaDevices.getUserMedia({ video: true })
      addDebugInfo('âœ… åŸºæœ¬ã‚¢ã‚¯ã‚»ã‚¹æ¨©å–å¾—æˆåŠŸ')
      // æ¨©é™å–å¾—ç”¨ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
      tempStream.getTracks().forEach(track => track.stop())

      // åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã‚’ç¢ºèª
      const devices = await navigator.mediaDevices.enumerateDevices()
      const videoDevices = devices.filter(device => device.kind === 'videoinput')
      addDebugInfo(`ğŸ“¹ ã‚«ãƒ¡ãƒ©ãƒ‡ãƒã‚¤ã‚¹: ${videoDevices.length}å€‹æ¤œå‡º`)

      // Quest/HMDç’°å¢ƒã®æ¤œå‡º
      const isQuestBrowser = navigator.userAgent.toLowerCase().includes('quest') || 
                             navigator.userAgent.toLowerCase().includes('oculus') || 
                             navigator.userAgent.toLowerCase().includes('meta')

      let stream: MediaStream

      if (isQuestBrowser && videoDevices.length > 0) {
        addDebugInfo('ğŸ¥½ Questç’°å¢ƒ - ãƒ‡ãƒã‚¤ã‚¹å€‹åˆ¥æŒ‡å®šã§ã‚¢ã‚¯ã‚»ã‚¹')
        
        // å¾Œæ–¹ã‚«ãƒ¡ãƒ©ï¼ˆãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼ã‚«ãƒ¡ãƒ©ï¼‰ã‚’æ¢ã™
        const backCamera = videoDevices.find(device => 
          device.label.toLowerCase().includes('back') || 
          device.label.toLowerCase().includes('rear') ||
          device.label.toLowerCase().includes('environment')
        ) || videoDevices[videoDevices.length - 1] // æœ€å¾Œã®ãƒ‡ãƒã‚¤ã‚¹ã‚’è©¦è¡Œ

        addDebugInfo(`ğŸ¯ é¸æŠãƒ‡ãƒã‚¤ã‚¹: ${backCamera.label || 'Unknown'}`)
        
        // å‚è€ƒã‚³ãƒ¼ãƒ‰ã¨åŒã˜ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šdeviceIdã§æ˜ç¤ºçš„ã«æŒ‡å®š
        stream = await navigator.mediaDevices.getUserMedia({
          video: { deviceId: { exact: backCamera.deviceId } }
        })
      } else {
        addDebugInfo('ğŸ’» é€šå¸¸ç’°å¢ƒ - facingModeæŒ‡å®š')
        // é€šå¸¸ç’°å¢ƒã§ã¯ facingMode ã§èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’æŒ‡å®š
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'environment' }
        })
      }
      
      addDebugInfo('âœ… ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ å–å¾—æˆåŠŸ')

      if (videoRef.current) {
        const video = videoRef.current
        
        // å‚è€ƒã‚³ãƒ¼ãƒ‰ã¨åŒã˜é †åºï¼šå±æ€§è¨­å®šâ†’ã‚¹ãƒˆãƒªãƒ¼ãƒ è¨­å®š
        addDebugInfo('ğŸ“º videoå±æ€§è¨­å®šä¸­...')
        video.autoplay = true
        video.playsInline = true
        
        addDebugInfo('ğŸ“º ã‚¹ãƒˆãƒªãƒ¼ãƒ è¨­å®šä¸­...')
        video.srcObject = stream
        
        // å‚è€ƒã‚³ãƒ¼ãƒ‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šautoplayã«ä»»ã›ã¦ã€ã‚·ãƒ³ãƒ—ãƒ«ã«ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹
        addDebugInfo('ğŸš€ ã‚¹ã‚­ãƒ£ãƒ³å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™')
        setIsScanning(true)
        
        // scanFrame()ã¯useEffectã§è‡ªå‹•å®Ÿè¡Œã•ã‚Œã‚‹ã®ã§ã€ã“ã“ã§ã¯å‘¼ã°ãªã„
      }
    } catch (error) {
      addDebugInfo(`âŒ ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: ${error}`)
      setError('ã‚«ãƒ¡ãƒ©ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“')
    }
  }, [])

  const stopScanning = () => {
    setIsScanning(false)
    hasLoggedScanStart.current = false
    frameCount.current = 0
    if (videoRef.current?.srcObject) {
      const tracks = (videoRef.current.srcObject as MediaStream).getTracks()
      tracks.forEach((track) => track.stop())
    }
  }

  const scanFrame = () => {
    if (!videoRef.current || !canvasRef.current || !isScanning) {
      addDebugInfo(`âš ï¸ ã‚¹ã‚­ãƒ£ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ æ¡ä»¶æœªæº€è¶³: video=${!!videoRef.current}, canvas=${!!canvasRef.current}, scanning=${isScanning}`)
      return
    }

    const video = videoRef.current
    const canvas = canvasRef.current
    const context = canvas.getContext('2d')

    // åˆå›ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
    if (!hasLoggedScanStart.current) {
      addDebugInfo(`ğŸ” ã‚¹ã‚­ãƒ£ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ é–‹å§‹: readyState=${video.readyState}, HAVE_ENOUGH_DATA=${video.HAVE_ENOUGH_DATA}`)
      addDebugInfo(`ğŸ“ Videoè§£åƒåº¦: ${video.videoWidth}x${video.videoHeight}`)
      addDebugInfo(`ğŸ“º VideoçŠ¶æ…‹: paused=${video.paused}, ended=${video.ended}`)
      hasLoggedScanStart.current = true
    }

    if (video.readyState === video.HAVE_ENOUGH_DATA) {
      frameCount.current++
      
      // 30ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†çŠ¶æ³ã‚’å ±å‘Š
      if (frameCount.current % 30 === 1) {
        addDebugInfo(`ğŸ”„ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ä¸­... (${frameCount.current}ãƒ•ãƒ¬ãƒ¼ãƒ ç›®)`)
      }

      // ãƒ“ãƒ‡ã‚ªã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ãªãŒã‚‰ã€é©åˆ‡ãªã‚µã‚¤ã‚ºã§ã‚­ãƒ£ãƒ³ãƒã‚¹ã«æç”»
      const videoAspect = video.videoWidth / video.videoHeight
      const canvasWidth = 640
      const canvasHeight = canvasWidth / videoAspect

      // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã‚’è¨­å®š
      canvas.width = canvasWidth
      canvas.height = canvasHeight

      // ãƒ“ãƒ‡ã‚ªå…¨ä½“ã‚’æç”»
      context?.drawImage(video, 0, 0, canvasWidth, canvasHeight)

      // ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›ã¨ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿
      const imageData = context?.getImageData(0, 0, canvasWidth, canvasHeight)
      if (imageData) {
        const data = imageData.data
        for (let i = 0; i < data.length; i += 4) {
          // ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
          const gray = data[i] * 0.299 + data[i + 1] * 0.587 + data[i + 2] * 0.114

          // ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿
          const contrast = 1.5
          const factor = (259 * (contrast + 255)) / (255 * (259 - contrast))
          const newGray = factor * (gray - 128) + 128

          // RGBã™ã¹ã¦ã«åŒã˜å€¤ã‚’è¨­å®š
          data[i] = data[i + 1] = data[i + 2] = Math.max(0, Math.min(255, newGray))
        }
        context?.putImageData(imageData, 0, 0)

        // QRã‚³ãƒ¼ãƒ‰æ¤œå‡ºã‚’è¤‡æ•°ã®å‘ãã§è©¦è¡Œ
        const angles = [0, 90, 180, 270]
        
        // 60ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«QRæ¤œå‡ºå‡¦ç†çŠ¶æ³ã‚’å ±å‘Š
        if (frameCount.current % 60 === 1) {
          addDebugInfo(`ğŸ” QRã‚³ãƒ¼ãƒ‰æ¤œå‡ºå‡¦ç†å®Ÿè¡Œä¸­...`)
        }
        
        for (const angle of angles) {
          if (angle > 0) {
            // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’å›è»¢
            const tempCanvas = document.createElement('canvas')
            const tempContext = tempCanvas.getContext('2d')
            if (!tempContext) continue

            if (angle === 90 || angle === 270) {
              tempCanvas.width = canvasHeight
              tempCanvas.height = canvasWidth
            } else {
              tempCanvas.width = canvasWidth
              tempCanvas.height = canvasHeight
            }

            tempContext.translate(tempCanvas.width / 2, tempCanvas.height / 2)
            tempContext.rotate((angle * Math.PI) / 180)
            tempContext.drawImage(canvas, -canvasWidth / 2, -canvasHeight / 2)

            const rotatedImageData = tempContext.getImageData(
              0,
              0,
              tempCanvas.width,
              tempCanvas.height,
            )
            const code = jsQR(rotatedImageData.data, tempCanvas.width, tempCanvas.height)
            if (code && code.data && code.data.trim().length >= 10) {
              addDebugInfo(`âœ… QRã‚³ãƒ¼ãƒ‰æ¤œå‡ºæˆåŠŸ (å›è»¢è§’åº¦: ${angle}åº¦)`)
              onScan(code.data)
              stopScanning()
              return
            }
          } else {
            const code = jsQR(data, canvasWidth, canvasHeight)
            if (code && code.data && code.data.trim().length >= 10) {
              addDebugInfo('âœ… QRã‚³ãƒ¼ãƒ‰æ¤œå‡ºæˆåŠŸ')
              onScan(code.data)
              stopScanning()
              return
            }
          }
        }
      }
    }

    if (isScanning) {
      requestAnimationFrame(scanFrame)
    }
  }

  // isScanningçŠ¶æ…‹ãŒå¤‰æ›´ã•ã‚ŒãŸã¨ãã«scanFrame()ã‚’å®Ÿè¡Œ
  useEffect(() => {
    if (isScanning) {
      addDebugInfo('âœ… isScanning=trueæ¤œå‡º - scanFrameé–‹å§‹')
      scanFrame()
    }
  }, [isScanning])

  useEffect(() => {
    return () => {
      stopScanning()
    }
  }, [])

  return {
    videoRef,
    canvasRef,
    startScanning,
    stopScanning,
    isScanning,
    error,
    debugInfo,
  }
}
